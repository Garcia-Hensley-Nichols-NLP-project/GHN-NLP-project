{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "\n",
    "from acquire import scrape_github_data\n",
    "from prepare import words\n",
    "\n",
    "from env import github_token, github_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for modeling... and stuff\n",
    "\n",
    "import pandas as pd\n",
    "from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords, prep_article_data, words\n",
    "from acquire import scrape_github_data\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Decision Tree and Random Forest ;D\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run scraping function\n",
    "# data = scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             500 non-null    object\n",
      " 1   language         470 non-null    object\n",
      " 2   readme_contents  500 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Turn scraped data into raw df\n",
    "# df = pd.DataFrame(data)\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "\n",
    "\n",
    "#Check returned df \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repo', 'language', 'readme', 'clean', 'stemmed', 'lemmatized',\n",
       "       'contains_python_keywords', 'contains_cpp_keywords',\n",
       "       'contains_js_keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = words(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other         277\n",
       "Python        104\n",
       "JavaScript     78\n",
       "C++            41\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 1) (120, 1) (100, 1)\n",
      "(280, 1) (120, 1) (100, 1)\n",
      "(280, 1) (120, 1) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make copies of df with prepared columns and target\n",
    "clean_df = df.copy()[['language', 'clean']]\n",
    "stem_df = df.copy()[['language', 'stemmed']]\n",
    "lem_df = df.copy()[['language', 'lemmatized']]\n",
    "\n",
    "\n",
    "# Get splits for each of the above dfs and isolate target\n",
    "X_clean = clean_df[['clean']]\n",
    "y_clean = clean_df.language\n",
    "\n",
    "X_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=.2, random_state=302)\n",
    "X_clean_train, X_clean_validate, y_clean_train, y_clean_validate  = train_test_split(X_clean_train, y_clean_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_clean_train.shape, X_clean_validate.shape, X_clean_test.shape)\n",
    "\n",
    "X_stem = stem_df[['stemmed']]\n",
    "y_stem = stem_df.language\n",
    "\n",
    "X_stem_train, X_stem_test, y_stem_train, y_stem_test = train_test_split(X_stem, y_stem, test_size=.2, random_state=302)\n",
    "X_stem_train, X_stem_validate, y_stem_train, y_stem_validate  = train_test_split(X_stem_train, y_stem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_stem_train.shape, X_stem_validate.shape, X_stem_test.shape)\n",
    "\n",
    "X_lem = lem_df[['lemmatized']]\n",
    "y_lem = lem_df.language\n",
    "\n",
    "X_lem_train, X_lem_test, y_lem_train, y_lem_test = train_test_split(X_lem, y_lem, test_size=.2, random_state=302)\n",
    "X_lem_train, X_lem_validate, y_lem_train, y_lem_validate  = train_test_split(X_lem_train, y_lem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_lem_train.shape, X_lem_validate.shape, X_lem_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Clean\" models\n",
    "cv_clean = CountVectorizer()\n",
    "tfidf_clean = TfidfVectorizer()\n",
    "\n",
    "cv_clean_bow = cv_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "tf_clean_bow = tfidf_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "\n",
    "# Check cv bag of words\n",
    "cv_clean_bow.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tfidf bag of words\n",
    "tf_clean_bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 1 score: 0.825\n",
      "TF IDF tree 1 score: 0.8464285714285714\n"
     ]
    }
   ],
   "source": [
    "# Make and fit decision tree object for cv_clean_bow\n",
    "cv_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree1.fit(cv_clean_bow, y_clean_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_clean_bow\n",
    "tf_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree1.fit(tf_clean_bow, y_clean_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 1 score: {cv_tree1.score(cv_clean_bow, y_clean_train)}')\n",
    "print(f'TF IDF tree 1 score: {tf_tree1.score(tf_clean_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 2 score: 0.8214285714285714\n",
      "TF IDF tree 2 score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# \"Stemmed\" models\n",
    "cv_stem = CountVectorizer()\n",
    "tfidf_stem = TfidfVectorizer()\n",
    "\n",
    "# Bags\n",
    "cv_stem_bow = cv_stem.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem_bow = tfidf_stem.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit decision tree object for cv_stem_bow\n",
    "cv_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree2.fit(cv_stem_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_stem_bow\n",
    "tf_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree2.fit(tf_stem_bow, y_stem_train)\n",
    "\n",
    "\n",
    "#Get tree score\n",
    "print(f'CV tree 2 score: {cv_tree2.score(cv_stem_bow, y_stem_train)}')\n",
    "#Get tree score\n",
    "print(f'TF IDF tree 2 score: {tf_tree2.score(tf_stem_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree score: 0.825\n",
      "TFIDF tree score: 0.8392857142857143\n"
     ]
    }
   ],
   "source": [
    "# \"Lemmatized\" models\n",
    "cv_lem = CountVectorizer()\n",
    "tfidf_lem = TfidfVectorizer()\n",
    "\n",
    "cv_lem_bow = cv_lem.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem_bow = tfidf_lem.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem_bow\n",
    "cv_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree3.fit(cv_lem_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_lem_bow\n",
    "tf_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree3.fit(tf_lem_bow, y_lem_train)\n",
    "\n",
    "# Output tree scores\n",
    "print(f'CV tree score: {cv_tree3.score(cv_lem_bow, y_lem_train)}') \n",
    "print(f'TFIDF tree score: {tf_tree3.score(tf_lem_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV_clean': 0.825,\n",
       " 'CV_stem': 0.8214285714285714,\n",
       " 'CV_lem': 0.825,\n",
       " 'TF/IDF_clean': 0.8464285714285714,\n",
       " 'TF/IDF_stem': 0.85,\n",
       " 'TF/IDF_lem': 0.8392857142857143}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_training_scores= {\n",
    "    'CV_clean': cv_tree1.score(cv_clean_bow, y_clean_train),\n",
    "    'CV_stem': cv_tree2.score(cv_stem_bow, y_stem_train),\n",
    "    'CV_lem': cv_tree3.score(cv_lem_bow, y_lem_train),\n",
    "    'TF/IDF_clean': tf_tree1.score(tf_clean_bow, y_clean_train),\n",
    "    'TF/IDF_stem': tf_tree2.score(tf_stem_bow, y_stem_train),\n",
    "    'TF/IDF_lem': tf_tree3.score(tf_lem_bow, y_lem_train)\n",
    "}\n",
    "\n",
    "dec_tree_training_scores\n",
    "#pd.DataFrame(dec_tree_training_scores, index=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways: Both vectorizers had scored the same on clean, stemmed, and lemmatized preparations of README text in previous evaluations. Current version of text preparations have models using TF/IDF vectorizers scoring higher on train split.\n",
    "\n",
    "### Update (16-May-2022): Data increased from 100 to 500 records. TF/IDF vectorizers still scoring higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_clean_bow_val = tfidf_clean.transform(X_clean_validate.clean)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "tf_tree1.score(tf_clean_bow_val, y_clean_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_stem_bow_val = tfidf_stem.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Get tf_tree2 score on validate\n",
    "tf_tree2.score(tf_stem_bow_val, y_stem_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_lem_bow_val = tfidf_lem.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "\n",
    "#Get tf_tree3 score on validate\n",
    "tf_tree3.score(tf_lem_bow_val, y_lem_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models, 100 estimators, max depth 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 1 score: 0.8035714285714286\n",
      "TF IDF RF 1 score: 0.8428571428571429\n",
      "CV RF 2 score: 0.8285714285714286\n",
      "TF IDF RF 2 score: 0.8821428571428571\n",
      "CV RF 3 score: 0.8035714285714286\n",
      "TF IDF RF 3 score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Make vectorizer objects\n",
    "cv_clean2 = CountVectorizer()\n",
    "tfidf_clean2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean2_bow = cv_clean2.fit_transform(X_clean_train.clean)\n",
    "tf_clean2_bow = tfidf_clean2.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit random forest object for cv_clean2_bow\n",
    "cv_rf1 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf1.fit(cv_clean2_bow, y_clean_train)\n",
    "\n",
    "#Make and fit random forest object for tf_clean2_bow\n",
    "tf_rf1 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf1.fit(tf_clean2_bow, y_clean_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 1 score: {cv_rf1.score(cv_clean2_bow, y_clean_train)}')\n",
    "print(f'TF IDF RF 1 score: {tf_rf1.score(tf_clean2_bow, y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem2 = CountVectorizer()\n",
    "tfidf_stem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem2_bow = cv_stem2.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem2_bow = tfidf_stem2.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit random object for cv_stem2_bow\n",
    "cv_rf2 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf2.fit(cv_stem2_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_stem2_bow\n",
    "tf_rf2 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf2.fit(tf_stem2_bow, y_stem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 2 score: {cv_rf2.score(cv_stem2_bow, y_stem_train)}')\n",
    "print(f'TF IDF RF 2 score: {tf_rf2.score(tf_stem2_bow, y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem2 = CountVectorizer()\n",
    "tfidf_lem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem2_bow = cv_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem2_bow = tfidf_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem2_bow\n",
    "cv_rf3 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf3.fit(cv_lem2_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_lem2_bow\n",
    "tf_rf3 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf3.fit(tf_lem2_bow, y_lem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 3 score: {cv_rf3.score(cv_lem2_bow, y_lem_train)}')\n",
    "print(f'TF IDF RF 3 score: {tf_rf3.score(tf_lem2_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both vectorizers scoring the same on training split for all text preparations. All move on to validate.\n",
    "\n",
    "### Update (16-May-2022 11:15) TF/IDF vectorizers score higher than count vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF IDF RF 3 score on validate: 0.675\n",
      "TF IDF RF 3 score on validate: 0.7\n",
      "TF IDF RF 3 score on validate: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "#cv_clean2_bow_val = cv_clean2.transform(X_clean_validate.clean)\n",
    "#cv_stem2_bow_val = cv_stem2.transform(X_stem_validate.stemmed)\n",
    "#cv_lem2_bow_val = cv_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output CV RF scores\n",
    "#print(f'CV RF 1 score on validate: {cv_rf1.score(cv_clean2_bow_val, y_clean_validate)}')\n",
    "#print(f'CV RF 2 score on validate: {cv_rf2.score(cv_stem2_bow_val, y_stem_validate)}')\n",
    "#print(f'CV RF 3 score on validate: {cv_rf3.score(cv_lem2_bow_val, y_lem_validate)}')\n",
    "\n",
    "# Transform TF IDF vectorizers on validate\n",
    "tf_clean2_bow_val = tfidf_clean2.transform(X_clean_validate.clean)\n",
    "tf_stem2_bow_val = tfidf_stem2.transform(X_stem_validate.stemmed)\n",
    "tf_lem2_bow_val = tfidf_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output TF IDF RF scores\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf1.score(tf_clean2_bow_val, y_clean_validate)}')\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf2.score(tf_stem2_bow_val, y_stem_validate)}')\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf3.score(tf_lem2_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized text prep for both vectorizers score highest, but TF IDF outscores CV. Significant drop off for both vectorizers on all text preparations, though. Random Forest model using TF IDF vectorizer on lemmatized text moves on to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF IDF RF 3 score on validate: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Transform TF IDF vectorizer on test \n",
    "tf_stem2_bow_test = tfidf_lem2.transform(X_stem_test.stemmed)\n",
    "\n",
    "# Output model's score on test\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf3.score(tf_stem2_bow_test, y_stem_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model (100 estimators, max depth 15) using TD IDF vectorizer on lemmatized text is 45% accurate on unseen data. (10% better than Decision Tree tested on previous version of data; on current version Random Forest and Decision Tree model both score 45%.)\n",
    "\n",
    "### Update (16-May-2022 11:12) Increased accuracy on larger dataset to 52%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes models, alpha 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV NB 1 score: 0.525\n",
      "TF IDF NB 1 score: 0.525\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_clean3 = CountVectorizer()\n",
    "tfidf_clean3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean3_bow = cv_clean3.fit_transform(X_clean_train.clean)\n",
    "tf_clean3_bow = tfidf_clean3.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_clean3_bow\n",
    "cv_nb1 = CategoricalNB(alpha=0.5, min_categories=cv_clean3_bow.toarray().shape[1]) # min_categories kwarg to ensure model is fed a consistent number of categories\n",
    "cv_nb1.fit(cv_clean3_bow.toarray(), y_clean_train) # Naive Bayes requires dense data\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_clean3_bow\n",
    "tf_nb1 = CategoricalNB(alpha=0.5, min_categories=cv_clean3_bow.toarray().shape[1])\n",
    "tf_nb1.fit(tf_clean3_bow.toarray(), y_clean_train) \n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 1 score: {cv_nb1.score(cv_clean3_bow.toarray(), y_clean_train)}')\n",
    "print(f'TF IDF NB 1 score: {tf_nb1.score(tf_clean3_bow.toarray(), y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem3 = CountVectorizer()\n",
    "tfidf_stem3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem3_bow = cv_stem3.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem3_bow = tfidf_stem3.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_stem3_bow\n",
    "cv_nb2 = CategoricalNB(alpha=0.5, min_categories=cv_stem3_bow.toarray().shape[1])\n",
    "cv_nb2.fit(cv_stem3_bow.toarray(), y_stem_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_stem3_bow\n",
    "tf_nb2 = CategoricalNB(alpha=0.5, min_categories=cv_stem3_bow.toarray().shape[1])\n",
    "tf_nb2.fit(tf_stem3_bow.toarray(), y_stem_train)\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 2 score: {cv_nb2.score(cv_stem3_bow.toarray(), y_stem_train)}')\n",
    "print(f'TF IDF NB 2 score: {tf_nb2.score(tf_stem3_bow.toarray(), y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem3 = CountVectorizer()\n",
    "tfidf_lem3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem3_bow = cv_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem3_bow = tfidf_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_lem3_bow\n",
    "cv_nb3 = CategoricalNB(alpha=0.5, min_categories=cv_lem3_bow.toarray().shape[1])\n",
    "cv_nb3.fit(cv_lem3_bow.toarray(), y_lem_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_lem3_bow\n",
    "tf_nb3 = CategoricalNB(alpha=0.5, min_categories=cv_lem3_bow.toarray().shape[1])\n",
    "tf_nb3.fit(tf_lem3_bow.toarray(), y_lem_train)\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 3 score: {cv_nb3.score(cv_lem3_bow.toarray(), y_lem_train)}')\n",
    "print(f'TF IDF NB 3 score: {tf_nb3.score(tf_lem3_bow.toarray(), y_lem_train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes models score significantly lower than DT and RF on training data. Equal scores across text preparations and vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV NB 1 score on validate: 0.5833333333333334\n",
      "CV NB 2 score on validate: 0.5833333333333334\n",
      "CV NB 3 score on validate: 0.5833333333333334\n",
      "TF/IDF NB 1 score on validate: 0.5833333333333334\n",
      "TF/IDF NB 2 score on validate: 0.5833333333333334\n",
      "TF/IDF NB 3 score on validate: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Transform count vectorizers on validate\n",
    "cv_clean3_bow_val = cv_clean3.transform(X_clean_validate.clean)\n",
    "cv_stem3_bow_val = cv_stem3.transform(X_stem_validate.stemmed)\n",
    "cv_lem3_bow_val = cv_lem3.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "tf_clean3_bow_val = tfidf_clean3.transform(X_clean_validate.clean)\n",
    "tf_stem3_bow_val = tfidf_stem3.transform(X_stem_validate.stemmed)\n",
    "tf_lem3_bow_val = tfidf_lem3.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output CV NB scores\n",
    "print(f'CV NB 1 score on validate: {cv_nb1.score(cv_clean3_bow_val.toarray(), y_clean_validate)}')\n",
    "print(f'CV NB 2 score on validate: {cv_nb2.score(cv_stem3_bow_val.toarray(), y_stem_validate)}')\n",
    "print(f'CV NB 3 score on validate: {cv_nb3.score(cv_lem3_bow_val.toarray(), y_lem_validate)}')\n",
    "\n",
    "# Output CV NB scores\n",
    "print(f'TF/IDF NB 1 score on validate: {tf_nb1.score(tf_clean3_bow_val.toarray(), y_clean_validate)}')\n",
    "print(f'TF/IDF NB 2 score on validate: {tf_nb2.score(tf_stem3_bow_val.toarray(), y_stem_validate)}')\n",
    "print(f'TF/IDF NB 3 score on validate: {tf_nb3.score(tf_lem3_bow_val.toarray(), y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV clean BOW on validate: (24, 5892)\n",
      "CV stem BOW on validate: (24, 4954)\n",
      "CV lem BOW on validate: (24, 5547)\n",
      "TF/IDF clean BOW on validate: (24, 5892)\n",
      "TF/IDF stem BOW on validate: (24, 4954)\n",
      "TF/IDF lem BOW on validate: (24, 5547)\n"
     ]
    }
   ],
   "source": [
    "print(f'CV clean BOW on validate: {cv_clean3_bow_val.toarray().shape}')\n",
    "print(f'CV stem BOW on validate: {cv_stem3_bow_val.toarray().shape}')\n",
    "print(f'CV lem BOW on validate: {cv_lem3_bow_val.toarray().shape}')\n",
    "print(f'TF/IDF clean BOW on validate: {tf_clean3_bow_val.toarray().shape}')\n",
    "print(f'TF/IDF stem BOW on validate: {tf_stem3_bow_val.toarray().shape}')\n",
    "print(f'TF/IDF lem BOW on validate: {tf_lem3_bow_val.toarray().shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5892"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_clean3_bow.toarray().shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<56x5892 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11246 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_clean3_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make functions to speed up modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_cv_dt_score (text_data, target, max_depth, ngram_range=False, train_split=True):\n",
    "    #'''\n",
    "    #Takes in text_data, a target variable, an optional ngram range argument (min_n, max_n) for a Count Vectorizer object, and a max_depth kwarg for a Decision Tree,\n",
    "    #and returns a bag of words (bow), the Decision Tree object and its accuracy score on the train split.\n",
    "    #'''\n",
    "    #cv = CountVectorizer(ngram_range)\n",
    "    #bow = cv.fit_transform(text_data)\n",
    "    #tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    #tree.fit(bow, target)\n",
    "    \n",
    "    #if train_split:\n",
    "        #dt_score = tree.score(bow, target)\n",
    "        #return tree, bow, dt_score\n",
    "    #else:\n",
    "        #print('Use tree and bow returned from train split to get score on validate/test split.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_tfidf_dt_score (text_data, target, depth, train_split=True):\n",
    "    #'''\n",
    "    #Takes in text_data, a target variable, and a depth(max_depth) kwarg for a Decision Tree model,\n",
    "    #and returns the Decision Tree object and an accompanying accuracy score for the model.\n",
    "    #'''\n",
    "    #tfidf = TfidfVectorizer()\n",
    "    #bow = tfidf.fit_transform(text_data)\n",
    "    #tree = DecisionTreeClassifier(max_depth=depth)\n",
    "    #tree.fit(bow, target)\n",
    "\n",
    "    #if train_split:\n",
    "        #dt_score = tree.score(bow, target)\n",
    "    #else:\n",
    "        #raise Exception('')\n",
    "\n",
    "    #return tree, dt_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_cv_rf_score(text_data, target, depth, n_estimators, train_split=True):\n",
    "    #'''\n",
    "    #Takes in text data, a target variable, depth and n_estimators kwargs for a Random Forest model,\n",
    "    #and returns the Random Forest object and an accompanying accuracy score for the model.\n",
    "    #'''\n",
    "    #cv = CountVectorizer()\n",
    "    #bow = cv.fit_transform(text_data)\n",
    "    #rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth)\n",
    "    #rf.fit(bow, target)\n",
    "    \n",
    "    #if train_split:\n",
    "        #rf_score = rf.score(bow, target)\n",
    "    #else:\n",
    "        #bow = cv.transform(text_data)\n",
    "        #rf_score = rf.score(bow, target)\n",
    "    \n",
    "    #return rf, rf_score"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
