{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "\n",
    "from acquire import scrape_github_data\n",
    "from prepare import words\n",
    "\n",
    "from env import github_token, github_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for modeling... and stuff\n",
    "\n",
    "import pandas as pd\n",
    "from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords, prep_article_data, words\n",
    "from acquire import scrape_github_data\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Decision Tree and Random Forest ;D\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run scraping function\n",
    "# data = scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             100 non-null    object\n",
      " 1   language         96 non-null     object\n",
      " 2   readme_contents  100 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Turn scraped data into raw df\n",
    "# df = pd.DataFrame(data)\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "\n",
    "\n",
    "#Check returned df \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other         53\n",
       "Python        18\n",
       "C++           17\n",
       "JavaScript    12\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 1) (24, 1) (20, 1)\n",
      "(56, 1) (24, 1) (20, 1)\n",
      "(56, 1) (24, 1) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make copies of df with prepared columns and target\n",
    "clean_df = df.copy()[['language', 'clean']]\n",
    "stem_df = df.copy()[['language', 'stemmed']]\n",
    "lem_df = df.copy()[['language', 'lemmatized']]\n",
    "\n",
    "\n",
    "# Get splits for each of the above dfs and isolate target\n",
    "X_clean = clean_df[['clean']]\n",
    "y_clean = clean_df.language\n",
    "\n",
    "X_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=.2, random_state=302)\n",
    "X_clean_train, X_clean_validate, y_clean_train, y_clean_validate  = train_test_split(X_clean_train, y_clean_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_clean_train.shape, X_clean_validate.shape, X_clean_test.shape)\n",
    "\n",
    "X_stem = stem_df[['stemmed']]\n",
    "y_stem = stem_df.language\n",
    "\n",
    "X_stem_train, X_stem_test, y_stem_train, y_stem_test = train_test_split(X_stem, y_stem, test_size=.2, random_state=302)\n",
    "X_stem_train, X_stem_validate, y_stem_train, y_stem_validate  = train_test_split(X_stem_train, y_stem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_stem_train.shape, X_stem_validate.shape, X_stem_test.shape)\n",
    "\n",
    "X_lem = lem_df[['lemmatized']]\n",
    "y_lem = lem_df.language\n",
    "\n",
    "X_lem_train, X_lem_test, y_lem_train, y_lem_test = train_test_split(X_lem, y_lem, test_size=.2, random_state=302)\n",
    "X_lem_train, X_lem_validate, y_lem_train, y_lem_validate  = train_test_split(X_lem_train, y_lem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_lem_train.shape, X_lem_validate.shape, X_lem_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Clean\" models\n",
    "cv_clean = CountVectorizer()\n",
    "tfidf_clean = TfidfVectorizer()\n",
    "\n",
    "cv_clean_bow = cv_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "tf_clean_bow = tfidf_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "\n",
    "# Check cv bag of words\n",
    "cv_clean_bow.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tfidf bag of words\n",
    "tf_clean_bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 1 score: 0.8571428571428571\n",
      "TF IDF tree 1 score: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Make and fit decision tree object for cv_clean_bow\n",
    "cv_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree1.fit(cv_clean_bow, y_clean_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_clean_bow\n",
    "tf_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree1.fit(tf_clean_bow, y_clean_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 1 score: {cv_tree1.score(cv_clean_bow, y_clean_train)}')\n",
    "print(f'TF IDF tree 1 score: {tf_tree1.score(tf_clean_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 2 score: 0.8571428571428571\n",
      "TF IDF tree 2 score: 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "# \"Stemmed\" models\n",
    "cv_stem = CountVectorizer()\n",
    "tfidf_stem = TfidfVectorizer()\n",
    "\n",
    "# Bags\n",
    "cv_stem_bow = cv_stem.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem_bow = tfidf_stem.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit decision tree object for cv_stem_bow\n",
    "cv_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree2.fit(cv_stem_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_stem_bow\n",
    "tf_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree2.fit(tf_stem_bow, y_stem_train)\n",
    "\n",
    "\n",
    "#Get tree score\n",
    "print(f'CV tree 2 score: {cv_tree2.score(cv_stem_bow, y_stem_train)}')\n",
    "#Get tree score\n",
    "print(f'TF IDF tree 2 score: {tf_tree2.score(tf_stem_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree score: 0.8571428571428571\n",
      "TFIDF tree score: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# \"Lemmatized\" models\n",
    "cv_lem = CountVectorizer()\n",
    "tfidf_lem = TfidfVectorizer()\n",
    "\n",
    "cv_lem_bow = cv_lem.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem_bow = tfidf_lem.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem_bow\n",
    "cv_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree3.fit(cv_lem_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_lem_bow\n",
    "tf_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree3.fit(tf_lem_bow, y_lem_train)\n",
    "\n",
    "# Output tree scores\n",
    "print(f'CV tree score: {cv_tree3.score(cv_lem_bow, y_lem_train)}') \n",
    "print(f'TFIDF tree score: {tf_tree3.score(tf_lem_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV_clean': 0.8571428571428571,\n",
       " 'CV_stem': 0.8571428571428571,\n",
       " 'CV_lem': 0.8571428571428571,\n",
       " 'TFIDF_clean': 0.875,\n",
       " 'TFIDF_stem': 0.8928571428571429,\n",
       " 'TFIDF_lem': 0.9285714285714286}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_training_scores= {\n",
    "    'CV_clean': cv_tree1.score(cv_clean_bow, y_clean_train),\n",
    "    'CV_stem': cv_tree2.score(cv_stem_bow, y_stem_train),\n",
    "    'CV_lem': cv_tree3.score(cv_lem_bow, y_lem_train),\n",
    "    'TFIDF_clean': tf_tree1.score(tf_clean_bow, y_clean_train),\n",
    "    'TFIDF_stem': tf_tree2.score(tf_stem_bow, y_stem_train),\n",
    "    'TFIDF_lem': tf_tree3.score(tf_lem_bow, y_lem_train)\n",
    "}\n",
    "\n",
    "dec_tree_training_scores\n",
    "#pd.DataFrame(dec_tree_training_scores, index=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways: Both vectorizers had scored the same on clean, stemmed, and lemmatized preparations of README text in previous evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_clean_bow_val = tfidf_clean.transform(X_clean_validate.clean)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "tf_tree1.score(tf_clean_bow_val, y_clean_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_stem_bow_val = tfidf_stem.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Get tf_tree2 score on validate\n",
    "tf_tree2.score(tf_stem_bow_val, y_stem_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_lem_bow_val = tfidf_lem.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "\n",
    "#Get tf_tree3 score on validate\n",
    "tf_tree3.score(tf_lem_bow_val, y_lem_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models, 100 estimators, max depth 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 1 score: 0.9821428571428571\n",
      "TF IDF RF 1 score: 0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "# Make vectorizer objects\n",
    "cv_clean2 = CountVectorizer()\n",
    "tfidf_clean2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean2_bow = cv_clean2.fit_transform(X_clean_train.clean)\n",
    "tf_clean2_bow = tfidf_clean2.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit random forest object for cv_clean2_bow\n",
    "cv_rf1 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf1.fit(cv_clean2_bow, y_clean_train)\n",
    "\n",
    "#Make and fit random forest object for tf_clean2_bow\n",
    "tf_rf1 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf1.fit(tf_clean2_bow, y_clean_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 1 score: {cv_rf1.score(cv_clean2_bow, y_clean_train)}')\n",
    "print(f'TF IDF RF 1 score: {tf_rf1.score(tf_clean2_bow, y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem2 = CountVectorizer()\n",
    "tfidf_stem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem2_bow = cv_stem2.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem2_bow = tfidf_stem2.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit decision tree object for cv_stem2_bow\n",
    "cv_rf2 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf2.fit(cv_stem2_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_stem2_bow\n",
    "tf_rf2 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf2.fit(tf_stem2_bow, y_stem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 2 score: {cv_rf2.score(cv_stem2_bow, y_stem_train)}')\n",
    "print(f'TF IDF RF 2 score: {tf_rf2.score(tf_stem2_bow, y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem2 = CountVectorizer()\n",
    "tfidf_lem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem2_bow = cv_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem2_bow = tfidf_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem2_bow\n",
    "cv_rf3 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf3.fit(cv_lem2_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_lem2_bow\n",
    "tf_rf3 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf3.fit(tf_lem2_bow, y_lem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 3 score: {cv_rf3.score(cv_lem2_bow, y_lem_train)}')\n",
    "print(f'TF IDF RF 3 score: {tf_rf3.score(tf_lem2_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both vectorizers scoring the same on training split for all text preparations. All move on to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 1 score on validate: 0.5\n",
      "CV RF 2 score on validate: 0.5\n",
      "CV RF 3 score on validate: 0.5416666666666666\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "cv_clean2_bow_val = cv_clean2.transform(X_clean_validate.clean)\n",
    "cv_stem2_bow_val = cv_stem2.transform(X_stem_validate.stemmed)\n",
    "cv_lem2_bow_val = cv_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output CV RF scores\n",
    "print(f'CV RF 1 score on validate: {cv_rf1.score(cv_clean2_bow_val, y_clean_validate)}')\n",
    "print(f'CV RF 2 score on validate: {cv_rf2.score(cv_stem2_bow_val, y_stem_validate)}')\n",
    "print(f'CV RF 3 score on validate: {cv_rf3.score(cv_lem2_bow_val, y_lem_validate)}')\n",
    "\n",
    "# Transform TF IDF vectorizers on validate\n",
    "tf_clean2_bow_val = tfidf_clean2.transform(X_clean_validate.clean)\n",
    "tf_stem2_bow_val = tfidf_stem2.transform(X_stem_validate.stemmed)\n",
    "tf_lem2_bow_val = tfidf_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output TF IDF RF scores\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf1.score(tf_clean2_bow_val, y_clean_validate)}')\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf2.score(tf_stem2_bow_val, y_stem_validate)}')\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf3.score(tf_lem2_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized text prep for both vectorizers score highest, but TF IDF outscores CV. Significant drop off for both vectorizers on all text preparations, though. Random Forest model using TF IDF vectorizer on lemmatized text moves on to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF IDF RF 3 score on validate: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Transform TF IDF vectorizer on test \n",
    "tf_lem2_bow_test = tfidf_lem2.transform(X_lem_test.lemmatized)\n",
    "\n",
    "# Output model's score on test\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf3.score(tf_lem2_bow_test, y_lem_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model (100 estimators, max depth 15) using TD IDF vectorizer on lemmatized text is 45% accurate on unseen data. (10% better than Decision Tree tested on previous version of data; on current version Random Forest and Decision Tree model both score 45%.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes models, alpha 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV NB 1 score: 0.75\n",
      "TF IDF NB 1 score: 0.5357142857142857\n",
      "CV NB 2 score: 0.75\n",
      "TF IDF NB 2 score: 0.5357142857142857\n",
      "CV NB 3 score: 0.75\n",
      "TF IDF NB 3 score: 0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_clean3 = CountVectorizer()\n",
    "tfidf_clean3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean3_bow = cv_clean3.fit_transform(X_clean_train.clean)\n",
    "tf_clean3_bow = tfidf_clean3.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_clean3_bow\n",
    "cv_nb1 = CategoricalNB(alpha=0.5)\n",
    "cv_nb1.fit(cv_clean3_bow.toarray(), y_clean_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_clean3_bow\n",
    "tf_nb1 = CategoricalNB(alpha=0.5)\n",
    "tf_nb1.fit(tf_clean3_bow.toarray(), y_clean_train) # Naive Bayes requires dense data\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 1 score: {cv_nb1.score(cv_clean3_bow.toarray(), y_clean_train)}')\n",
    "print(f'TF IDF NB 1 score: {tf_nb1.score(tf_clean3_bow.toarray(), y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem3 = CountVectorizer()\n",
    "tfidf_stem3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem3_bow = cv_stem3.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem3_bow = tfidf_stem3.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_stem3_bow\n",
    "cv_nb2 = CategoricalNB(alpha=0.5)\n",
    "cv_nb2.fit(cv_stem3_bow.toarray(), y_stem_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_stem3_bow\n",
    "tf_nb2 = CategoricalNB(alpha=0.5)\n",
    "tf_nb2.fit(tf_stem3_bow.toarray(), y_stem_train)\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 2 score: {cv_nb2.score(cv_stem3_bow.toarray(), y_stem_train)}')\n",
    "print(f'TF IDF NB 2 score: {tf_nb2.score(tf_stem3_bow.toarray(), y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem3 = CountVectorizer()\n",
    "tfidf_lem3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem3_bow = cv_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem3_bow = tfidf_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_lem3_bow\n",
    "cv_nb3 = CategoricalNB(alpha=0.5)\n",
    "cv_nb3.fit(cv_lem3_bow.toarray(), y_lem_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_lem3_bow\n",
    "tf_nb3 = CategoricalNB(alpha=0.5)\n",
    "tf_nb3.fit(tf_lem3_bow.toarray(), y_lem_train)\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 3 score: {cv_nb3.score(cv_lem3_bow.toarray(), y_lem_train)}')\n",
    "print(f'TF IDF NB 3 score: {tf_nb3.score(tf_lem3_bow.toarray(), y_lem_train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes models score significantly lower on training data. Equal scores across text preparations. Count Vectorizer beats TF/IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix([[0, 0, 0, ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Transform count vectorizers on validate\n",
    "cv_clean3_bow_val = cv_clean3.transform(X_clean_validate.clean)\n",
    "cv_stem3_bow_val = cv_stem3.transform(X_stem_validate.stemmed)\n",
    "cv_lem3_bow_val = cv_lem3.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "pprint(cv_clean3_bow_val.todense()[10])\n",
    "\n",
    "# Output CV NB scores\n",
    "#print(f'CV NB 1 score on validate: {cv_nb1.score(cv_clean3_bow_val.todense(), y_clean_validate)}')\n",
    "#print(f'CV NB 2 score on validate: {cv_nb2.score(cv_stem3_bow_val.todense(), y_stem_validate)}')\n",
    "#print(f'CV NB 3 score on validate: {cv_nb3.score(cv_lem3_bow_val.todense(), y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_dec_tree(text_data, target, depth):\n",
    "    cv = CountVectorizer()\n",
    "    bow = cv.fit_transform(text_data)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
