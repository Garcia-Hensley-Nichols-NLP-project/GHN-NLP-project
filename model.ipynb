{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords, prep_article_data, words\n",
    "from acquire import scrape_github_data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Decision Tree and Random Forest ;D\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   repo                      100 non-null    object\n",
      " 1   language                  100 non-null    object\n",
      " 2   readme                    100 non-null    object\n",
      " 3   clean                     100 non-null    object\n",
      " 4   stemmed                   100 non-null    object\n",
      " 5   lemmatized                100 non-null    object\n",
      " 6   contains_python_keywords  100 non-null    int64 \n",
      " 7   contains_cpp_keywords     100 non-null    int64 \n",
      " 8   contains_js_keywords      100 non-null    int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 7.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>contains_python_keywords</th>\n",
       "      <th>contains_cpp_keywords</th>\n",
       "      <th>contains_js_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin/bitcoin</td>\n",
       "      <td>C++</td>\n",
       "      <td>Bitcoin Core integration/staging tree\\n=======...</td>\n",
       "      <td>bitcoin core integrationstaging tree httpsbitc...</td>\n",
       "      <td>bitcoin core integrationstag tree httpsbitcoin...</td>\n",
       "      <td>bitcoin core integrationstaging tree httpsbitc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitcoinbook/bitcoinbook</td>\n",
       "      <td>other</td>\n",
       "      <td>Code Examples: ![travis_ci](https://travis-ci....</td>\n",
       "      <td>code examples traviscihttpstravisciorgbitcoinb...</td>\n",
       "      <td>code exampl traviscihttpstravisciorgbitcoinboo...</td>\n",
       "      <td>code example traviscihttpstravisciorgbitcoinbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitcoin/bips</td>\n",
       "      <td>other</td>\n",
       "      <td>People wishing to submit BIPs, first should pr...</td>\n",
       "      <td>people wishing submit bips first propose idea ...</td>\n",
       "      <td>peopl wish submit bip first propos idea docume...</td>\n",
       "      <td>people wishing submit bips first propose idea ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bitcoinjs/bitcoinjs-lib</td>\n",
       "      <td>other</td>\n",
       "      <td># BitcoinJS (bitcoinjs-lib)\\n[![Github CI](htt...</td>\n",
       "      <td>bitcoinjs bitcoinjslib github cihttpsgithubcom...</td>\n",
       "      <td>bitcoinj bitcoinjslib github cihttpsgithubcomb...</td>\n",
       "      <td>bitcoinjs bitcoinjslib github cihttpsgithubcom...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spesmilo/electrum</td>\n",
       "      <td>Python</td>\n",
       "      <td>Electrum - Lightweight Bitcoin client\\n=======...</td>\n",
       "      <td>electrum lightweight bitcoin client licence mi...</td>\n",
       "      <td>electrum lightweight bitcoin client licenc mit...</td>\n",
       "      <td>electrum lightweight bitcoin client licence mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo language  \\\n",
       "0          bitcoin/bitcoin      C++   \n",
       "1  bitcoinbook/bitcoinbook    other   \n",
       "2             bitcoin/bips    other   \n",
       "3  bitcoinjs/bitcoinjs-lib    other   \n",
       "4        spesmilo/electrum   Python   \n",
       "\n",
       "                                              readme  \\\n",
       "0  Bitcoin Core integration/staging tree\\n=======...   \n",
       "1  Code Examples: ![travis_ci](https://travis-ci....   \n",
       "2  People wishing to submit BIPs, first should pr...   \n",
       "3  # BitcoinJS (bitcoinjs-lib)\\n[![Github CI](htt...   \n",
       "4  Electrum - Lightweight Bitcoin client\\n=======...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  bitcoin core integrationstaging tree httpsbitc...   \n",
       "1  code examples traviscihttpstravisciorgbitcoinb...   \n",
       "2  people wishing submit bips first propose idea ...   \n",
       "3  bitcoinjs bitcoinjslib github cihttpsgithubcom...   \n",
       "4  electrum lightweight bitcoin client licence mi...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  bitcoin core integrationstag tree httpsbitcoin...   \n",
       "1  code exampl traviscihttpstravisciorgbitcoinboo...   \n",
       "2  peopl wish submit bip first propos idea docume...   \n",
       "3  bitcoinj bitcoinjslib github cihttpsgithubcomb...   \n",
       "4  electrum lightweight bitcoin client licenc mit...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  bitcoin core integrationstaging tree httpsbitc...   \n",
       "1  code example traviscihttpstravisciorgbitcoinbo...   \n",
       "2  people wishing submit bips first propose idea ...   \n",
       "3  bitcoinjs bitcoinjslib github cihttpsgithubcom...   \n",
       "4  electrum lightweight bitcoin client licence mi...   \n",
       "\n",
       "   contains_python_keywords  contains_cpp_keywords  contains_js_keywords  \n",
       "0                         1                      1                     0  \n",
       "1                         0                      0                     0  \n",
       "2                         1                      1                     0  \n",
       "3                         1                      0                     1  \n",
       "4                         1                      1                     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data.json')\n",
    "\n",
    "df = words(df)\n",
    "\n",
    "#df.info()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 1) (24, 1) (20, 1)\n",
      "(56, 1) (24, 1) (20, 1)\n",
      "(56, 1) (24, 1) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make copies of df with prepared columns and target\n",
    "clean_df = df.copy()[['language', 'clean']]\n",
    "stem_df = df.copy()[['language', 'stemmed']]\n",
    "lem_df = df.copy()[['language', 'lemmatized']]\n",
    "\n",
    "\n",
    "# Get splits for each of the above dfs and isolate target\n",
    "X_clean = clean_df[['clean']]\n",
    "y_clean = clean_df.language\n",
    "\n",
    "X_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=.2, random_state=302)\n",
    "X_clean_train, X_clean_validate, y_clean_train, y_clean_validate  = train_test_split(X_clean_train, y_clean_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_clean_train.shape, X_clean_validate.shape, X_clean_test.shape)\n",
    "\n",
    "X_stem = stem_df[['stemmed']]\n",
    "y_stem = stem_df.language\n",
    "\n",
    "X_stem_train, X_stem_test, y_stem_train, y_stem_test = train_test_split(X_stem, y_stem, test_size=.2, random_state=302)\n",
    "X_stem_train, X_stem_validate, y_stem_train, y_stem_validate  = train_test_split(X_stem_train, y_stem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_stem_train.shape, X_stem_validate.shape, X_stem_test.shape)\n",
    "\n",
    "X_lem = lem_df[['lemmatized']]\n",
    "y_lem = lem_df.language\n",
    "\n",
    "X_lem_train, X_lem_test, y_lem_train, y_lem_test = train_test_split(X_lem, y_lem, test_size=.2, random_state=302)\n",
    "X_lem_train, X_lem_validate, y_lem_train, y_lem_validate  = train_test_split(X_lem_train, y_lem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_lem_train.shape, X_lem_validate.shape, X_lem_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make vectorizer objects for bags of words (clean_df)\n",
    "cv_clean = CountVectorizer()\n",
    "tfidf_clean = TfidfVectorizer()\n",
    "\n",
    "#Bags of words\n",
    "cv_clean_bow = cv_clean.fit_transform(X_clean_train.clean)\n",
    "tf_clean_bow = tfidf_clean.fit_transform(X_clean_train.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 1 score: 0.8571428571428571\n",
      "TF IDF tree 1 score: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "# Make and fit decision tree object for cv_clean_bow\n",
    "cv_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree1.fit(cv_clean_bow, y_clean_train)\n",
    "\n",
    "#Output tree score\n",
    "print(f'CV tree 1 score: {cv_tree1.score(cv_clean_bow, y_clean_train)}')\n",
    "\n",
    "#Make and fit decision tree object for tf_clean_bow\n",
    "tf_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree1.fit(tf_clean_bow, y_clean_train)\n",
    "\n",
    "#Output tree score\n",
    "print(f'TF IDF tree 1 score: {tf_tree1.score(tf_clean_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 2 score: 0.8571428571428571\n",
      "TF IDF tree 2 score: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "# \"Stemmed\" models\n",
    "cv_stem = CountVectorizer()\n",
    "tfidf_stem = TfidfVectorizer()\n",
    "\n",
    "# Bags\n",
    "cv_stem_bow = cv_stem.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem_bow = tfidf_stem.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit decision tree object for cv_stem_bow\n",
    "cv_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree2.fit(cv_stem_bow, y_stem_train)\n",
    "\n",
    "#Output tree score\n",
    "print(f'CV tree 2 score: {cv_tree2.score(cv_stem_bow, y_stem_train)}')\n",
    "\n",
    "#Make and fit decision tree object for tf_stem_bow\n",
    "tf_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree2.fit(tf_stem_bow, y_stem_train)\n",
    "\n",
    "#Output tree score\n",
    "print(f'TF IDF tree 2 score: {tf_tree2.score(tf_stem_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree score: 0.8571428571428571\n",
      "TFIDF tree score: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "# \"Lemmatized\" models\n",
    "cv_lem = CountVectorizer()\n",
    "tfidf_lem = TfidfVectorizer()\n",
    "\n",
    "cv_lem_bow = cv_lem.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem_bow = tfidf_lem.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem_bow\n",
    "cv_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree3.fit(cv_lem_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_lem_bow\n",
    "tf_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree3.fit(tf_lem_bow, y_lem_train)\n",
    "\n",
    "# Output tree scores\n",
    "print(f'CV tree score: {cv_tree3.score(cv_lem_bow, y_lem_train)}') \n",
    "print(f'TFIDF tree score: {tf_tree3.score(tf_lem_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV_clean': 0.8571428571428571,\n",
       " 'CV_stem': 0.8571428571428571,\n",
       " 'CV_lem': 0.8571428571428571,\n",
       " 'TFIDF_clean': 0.9107142857142857,\n",
       " 'TFIDF_stem': 0.9107142857142857,\n",
       " 'TFIDF_lem': 0.9107142857142857}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_training_scores= {\n",
    "    'CV_clean': cv_tree1.score(cv_clean_bow, y_clean_train),\n",
    "    'CV_stem': cv_tree2.score(cv_stem_bow, y_stem_train),\n",
    "    'CV_lem': cv_tree3.score(cv_lem_bow, y_lem_train),\n",
    "    'TFIDF_clean': tf_tree1.score(tf_clean_bow, y_clean_train),\n",
    "    'TFIDF_stem': tf_tree2.score(tf_stem_bow, y_stem_train),\n",
    "    'TFIDF_lem': tf_tree3.score(tf_lem_bow, y_lem_train)\n",
    "}\n",
    "\n",
    "dec_tree_training_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways: Both vectorizers scoring the same on clean, stemmed, and lemmatized versions of README text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_clean_bow_val = tfidf_clean.transform(X_clean_validate.clean)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "tf_tree1.score(tf_clean_bow_val, y_clean_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerable drop off. Probably overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_stem_bow_val = tfidf_stem.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "tf_tree2.score(tf_stem_bow_val, y_stem_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even worse dropoff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_lem_bow_val = tfidf_lem.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "tf_tree3.score(tf_lem_bow_val, y_lem_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized and stemmed preparations scored the same: 54.2%  Cleaned preparation scored 62.5% and will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_clean_bow_test = tfidf_clean.transform(X_clean_test.clean)\n",
    "\n",
    "tf_tree1.score(tf_clean_bow_test, y_clean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: Decision Tree model with a max depth of 5 and TFIDF Vectorizer, using \"clean\" version of README text, performs at 35% accuracy on unseen data.\n",
    "\n",
    "# Conclusions: Different types of models and adjustments to hyperparameters may yield better results."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
